{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best attack parameters given a hardware\n",
    "\n",
    "We assume the attack parameters are $n$ and $l$. Also, denote $g$ to be the number of ignored bits. \n",
    "\n",
    "$p = \\frac{2^l}{2^n}$ , this is a geometric random variable, thus we expect a collision after   $\\#queries = \\frac{2^n}{2^l} $\n",
    "\n",
    "Assume, we only accept digests that have certain number of zeros, denoted as $d$. Thus, we can pretend as we are working on small digests\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\#queries = \\frac{2^n}{2^l} \\\\\n",
    "&\\#queries_{sec} \\cdot t_{sec} = \\frac{2^n}{2^l} \\\\\n",
    "\\Rightarrow &n = log2\\left(\\#queries_{sec} \\cdot t_{sec} \\cdot 2^{n-l-d}  \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "We have three point of views of $\\#queries$\n",
    "- Senders: How many hashes they generate? \n",
    "    - Their speed will be affected by difficulty, but from their perspective the overall attack time doesn't change if the difficulty change (add explanation, later)\n",
    "    - $\\#snd\\_queries_{sec} = \\frac{\\#senders \\cdot \\#gen\\_hashes_{sec}} {2^{d}}$\n",
    "\n",
    "- Receivers: How many hashes they can query the dicitonary. \n",
    "    - In their world, the higher the difficulty the better chance of hitting collision (since digests are technically shorter).\n",
    "    - $\\#rcv\\_queries_{sec} = \\#receivers \\cdot \\#dict\\_queries_{sec} $\n",
    "\n",
    "- Bandwith: This is how many hashes the network can carry in a second. \n",
    "    - From their perspective, difficulty reduces the rate of transmitted messages. \n",
    "    - $bdwth_queries_{sec} $\n",
    "\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$\\#queries_{sec} := min\\left(snd\\_queries_{sec}, rcv\\_queries_{sec}, bdwth\\_queries_{sec}\\right)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server_memory=89000000000\n"
     ]
    }
   ],
   "source": [
    "# Numbers from Gros cluster, nancy, grid5000.fr\n",
    "nservers = 40\n",
    "server_memory = (96-7)*10^9 # 96 GB\n",
    "ncores_per_server = 36\n",
    "hashes_sec_core =  2^24 # 56 MB\n",
    "dict_queries_sec = 2^25.4227\n",
    "t_sec = 3600*11 # 31 * 24 * 3600\n",
    "\n",
    "hashes_sec_phase_i = 2^24.72\n",
    "\n",
    "# 1 core hashing power\n",
    "# thd2 sha_avx512_16way  elapsed 1.78sec i.e. 898392.92 hashes/sec = 2^19.777 hashes, 57.4971 M\n",
    "\n",
    "\n",
    "# Querying 100000000, took 2.22 sec i.e. 44977939.99 elm/sec = 2^25.4227 elm/sec \n",
    "\n",
    "\n",
    "def seconds_2_time(t):\n",
    "    from math import floor\n",
    "\n",
    "    t = float(t)\n",
    "    days  = floor(t/(3600*24))\n",
    "    t = t - days*24*3600\n",
    "\n",
    "    hours = floor(t/3600)\n",
    "    t = t - hours*3600\n",
    "    minutes = floor(t/60)\n",
    "    t = t - minutes*60\n",
    "\n",
    "    return f\"{days} days, {hours} hours, {minutes} mins, {floor(t)} sec\"\n",
    "\n",
    "print(f\"server_memory={server_memory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nqueries_sender(nsenders, hashes_sec_core, difficulty):\n",
    "    \"\"\" Return how many queries senders can generate per second \"\"\"\n",
    "\n",
    "    return nsenders*hashes_sec_core/(2**difficulty)\n",
    "\n",
    "\n",
    "def nqueries_receiver(nreceivers, dict_queries_sec):\n",
    "    \"\"\"\n",
    "    Return how many queries receivers can make in a second\n",
    "    \"\"\"\n",
    "    return nreceivers * dict_queries_sec\n",
    "\n",
    "def phase_i_time(l, difficulty, hashes_sec_phase_i):\n",
    "    \"\"\"\n",
    "    Return how many seconds it takes to complete phase_i\n",
    "    \"\"\"\n",
    "    return 2^l * 2^difficulty / (hashes_sec_phase_i)\n",
    "\n",
    "\n",
    "def largest_n(l,\n",
    "              nsenders,\n",
    "              nreceivers,\n",
    "              dict_queries_sec,\n",
    "              hashes_sec_core,\n",
    "              difficulty,\n",
    "              t_sec):\n",
    "\n",
    "    \"\"\"\n",
    "    Given an attack parameter what is the largest n can be attacked in t_sec\n",
    "    \"\"\"\n",
    "    from math import log2\n",
    "\n",
    "    nqueries_sec = min(nqueries_sender(nsenders, hashes_sec_core, difficulty),\n",
    "                   nqueries_receiver(nreceivers, dict_queries_sec))\n",
    "\n",
    "    return log2(nqueries_sec*t_sec) + l + difficulty\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_best_parameters(nservers,\n",
    "              server_memory,\n",
    "              ncores_per_server,\n",
    "              dict_queries_sec,\n",
    "              hashes_sec_core,\n",
    "              hashes_sec_phase_i,\n",
    "              t_sec,\n",
    "              phase_i_timeout=365*24*60*60):\n",
    "    \"\"\"\n",
    "    Find the attack parameters that can attack the largest possible n in t_sec\n",
    "    return dictionary contains attack parameters.\n",
    "    phase_i_timeout by default 365 days, since it can be done offline\n",
    "    phase_ii_reconstruct_timeout \n",
    "    \"\"\"\n",
    "\n",
    "    from math import log2\n",
    "    from itertools import product\n",
    "\n",
    "    memory = nservers * server_memory\n",
    "    val_size_bytes = 4 # one entry size in the dictionary\n",
    "    filling_rate = 0.93 # how many slots of the dictionary are used\n",
    "    l = log2(filling_rate * memory / val_size_bytes)\n",
    "\n",
    "    ncores = nservers * ncores_per_server\n",
    "\n",
    "    best_difficulty = 0\n",
    "    best_n = 0 # optimize: find largest n\n",
    "    best_nsenders = 0\n",
    "    best_time_phase_i = float('inf')\n",
    "    largest_difficulty = 40\n",
    "    \n",
    "    for nsenders, difficulty in product(range(1, ncores-nservers + 1), range(0, largest_difficulty)):\n",
    "        nreceivers = ncores - nsenders\n",
    "        n = largest_n(l,\n",
    "                      nsenders,\n",
    "                      nreceivers,\n",
    "                      dict_queries_sec,\n",
    "                      hashes_sec_core,\n",
    "                      difficulty,\n",
    "                      t_sec)\n",
    "\n",
    "#         if (nreceivers == nservers):\n",
    "#             print(f\"n={n}, l={l}, nsenders={nsenders}, difficulty={difficulty}\")\n",
    "\n",
    "        # better n, always update\n",
    "        t_phase_i = phase_i_time(l, difficulty, hashes_sec_phase_i)\n",
    "        \n",
    "        if (n > best_n  and t_phase_i <= phase_i_timeout):\n",
    "            best_n = n\n",
    "            best_difficulty = difficulty\n",
    "            best_nsenders = nsenders\n",
    "\n",
    "\n",
    "    return {\"n\": best_n, \"l\": l,\n",
    "            \"difficulty\": best_difficulty,\n",
    "            \"nsenders\": best_nsenders,\n",
    "            \"nreceivers\": ncores - nsenders}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 378 ms, sys: 110 Âµs, total: 378 ms\n",
      "Wall time: 378 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n': 89.31474092285998,\n",
       " 'l': 39.590317001173325,\n",
       " 'difficulty': 4,\n",
       " 'nsenders': 1400,\n",
       " 'nreceivers': 40}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "find_best_parameters(nservers,\n",
    "                     server_memory,\n",
    "                     ncores_per_server,\n",
    "                     dict_queries_sec,\n",
    "                     hashes_sec_core,\n",
    "                     hashes_sec_phase_i,\n",
    "                     t_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4507329 days, 14 hours, 41 mins, 42 sec'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seconds_2_time(phase_i_time(41.22258521667284, 22, hashes_sec_phase_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12348.8465753425"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N(4507329/365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.01843317972350"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N((365/4340)*24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.7",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
