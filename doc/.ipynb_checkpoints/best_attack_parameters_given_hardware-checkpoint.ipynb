{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best attack parameters given a hardware\n",
    "\n",
    "We assume the attack parameters are $n$ and $l$. Also, denote $g$ to be the number of ignored bits. \n",
    "\n",
    "$p = \\frac{2^l}{2^n}$ , this is a geometric random variable, thus we expect a collision after   $\\#queries = \\frac{2^n}{2^l} $\n",
    "\n",
    "Assume, we only accept digests that have certain number of zeros, denoted as $d$. Thus, we can pretend as we are working on small digests\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\#queries = \\frac{2^n}{2^l} \\\\\n",
    "&\\#queries_{sec} \\cdot t_{sec} = \\frac{2^n}{2^l} \\\\\n",
    "\\Rightarrow &n = log2\\left(\\#queries_{sec} \\cdot t_{sec} \\cdot 2^{n-l-d}  \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "We have three point of views of $\\#queries$\n",
    "- Senders: How many hashes they generate? \n",
    "    - Their speed will be affected by difficulty, but from their perspective the overall attack time doesn't change if the difficulty change (add explanation, later)\n",
    "    - $\\#snd\\_queries_{sec} = \\frac{\\#senders \\cdot \\#gen\\_hashes_{sec}} {2^{d}}$\n",
    "\n",
    "- Receivers: How many hashes they can query the dicitonary. \n",
    "    - In their world, the higher the difficulty the better chance of hitting collision (since digests are technically shorter).\n",
    "    - $\\#rcv\\_queries_{sec} = \\#receivers \\cdot \\#dict\\_queries_{sec} $\n",
    "\n",
    "- Bandwith: This is how many hashes the network can carry in a second. \n",
    "    - From their perspective, difficulty reduces the rate of transmitted messages. \n",
    "    - $bdwth_queries_{sec} $\n",
    "\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$\\#queries_{sec} := min\\left(snd\\_queries_{sec}, rcv\\_queries_{sec}, bdwth\\_queries_{sec}\\right)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbers from Gros cluster, nancy, grid5000.fr\n",
    "# find_dist overhead = 7%-9%\n",
    "# hash_16x_avx (nancy: gros) ≈ 2^24.87hash/sec\n",
    "# dict_add≈2^23.41 elm/sec\n",
    "# dict_lookup ≈ 2^24.9337 elm/sec\n",
    "# mpi_recv overhead = 10.71% (for regenerating message)\n",
    "\n",
    "\n",
    "nservers = 124\n",
    "server_memory = (96 - 20)*10^9 # 96 GB\n",
    "ncores_per_server = 18\n",
    "hashes_sec_core = 2^24.87\n",
    "dict_queries_sec = 2^21.963350\n",
    "t_sec =  2 * 24 * 3600\n",
    "# how many hashes can oure compressed file \n",
    "nhashes_stored = 2^60\n",
    "hashes_sec_phase_i = 2^24.72\n",
    "dict_add_sec = 2^23.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server_memory=76000000000\n"
     ]
    }
   ],
   "source": [
    "# 1 core hashing power\n",
    "# thd2 sha_avx512_16way  elapsed 1.78sec i.e. 898392.92 hashes/sec = 2^19.777 hashes, 57.4971 M\n",
    "\n",
    "\n",
    "# Querying 100000000, took 2.22 sec i.e. 44977939.99 elm/sec = 2^25.4227 elm/sec \n",
    "\n",
    "\n",
    "def seconds_2_time(t):\n",
    "    from math import floor\n",
    "\n",
    "    t = float(t)\n",
    "    days  = floor(t/(3600*24))\n",
    "    t = t - days*24*3600\n",
    "\n",
    "    hours = floor(t/3600)\n",
    "    t = t - hours*3600\n",
    "    minutes = floor(t/60)\n",
    "    t = t - minutes*60\n",
    "\n",
    "    return f\"{days} days, {hours} hours, {minutes} mins, {floor(t)} sec\"\n",
    "\n",
    "print(f\"server_memory={server_memory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regen_msg_time(nsenders,\n",
    "                   nreceivers,\n",
    "                   hashes_sec_core,\n",
    "                   dict_add_sec,\n",
    "                   difficulty,\n",
    "                   nhashes_stored):\n",
    "    \"\"\" return number of seconds needed to regenerate the long message\"\"\"\n",
    "    nsecs_sender = nhashes_stored / (nsenders*hashes_sec_core)\n",
    "    nsecs_receiver = (nhashes_stored/(2**difficulty)) \n",
    "    nsecs_receiver = nsecs_receiver / (nreceivers*dict_add_sec)\n",
    "    \n",
    "    return max(nsecs_receiver, nsecs_sender)\n",
    "\n",
    "\n",
    "def regen_msg_l(difficulty,\n",
    "                nhashes_stored):\n",
    "    \"\"\" return the max l can be constructed with difficulty \"\"\"\n",
    "    from math import log2\n",
    "    \n",
    "    return log2( (nhashes_stored/(2**difficulty)) )\n",
    "    \n",
    "def nqueries_sender(nsenders, hashes_sec_core, difficulty):\n",
    "    \"\"\" Return how many queries senders can generate per second \"\"\"\n",
    "\n",
    "    return nsenders*hashes_sec_core/(2**difficulty)\n",
    "\n",
    "\n",
    "def nqueries_receiver(nreceivers, dict_queries_sec):\n",
    "    \"\"\"\n",
    "    Return how many queries receivers can make in a second\n",
    "    \"\"\"\n",
    "    return nreceivers * dict_queries_sec\n",
    "\n",
    "def phase_i_time(l, difficulty, hashes_sec_phase_i):\n",
    "    \"\"\"\n",
    "    Return how many seconds it takes to complete phase_i\n",
    "    \"\"\"\n",
    "    return 2^l * 2^difficulty / (hashes_sec_phase_i)\n",
    "\n",
    "\n",
    "def largest_n(l,\n",
    "              nsenders,\n",
    "              nreceivers,\n",
    "              dict_queries_sec,\n",
    "              hashes_sec_core,\n",
    "              difficulty,\n",
    "              t_sec):\n",
    "\n",
    "    \"\"\"\n",
    "    Given an attack parameter what is the largest n can be attacked in t_sec\n",
    "    \"\"\"\n",
    "    from math import log2\n",
    "\n",
    "    nqueries_sec = min(nqueries_sender(nsenders, hashes_sec_core, difficulty),\n",
    "                   nqueries_receiver(nreceivers, dict_queries_sec))\n",
    "\n",
    "    return log2(nqueries_sec*t_sec) + l + difficulty\n",
    "\n",
    "\n",
    "\n",
    "def find_best_parameters(nservers,\n",
    "              server_memory,\n",
    "              ncores_per_server,\n",
    "              nhashes_stored,\n",
    "              dict_queries_sec,\n",
    "              dict_add_sec,\n",
    "              hashes_sec_core,\n",
    "              hashes_sec_phase_i,\n",
    "              t_sec,\n",
    "              phase_i_timeout=365*24*60*60):\n",
    "    \"\"\"\n",
    "    Find the attack parameters that can attack the largest possible n in t_sec\n",
    "    return dictionary contains attack parameters.\n",
    "    phase_i_timeout by default 365 days, since it can be done offline\n",
    "    phase_ii_reconstruct_timeout \n",
    "    \"\"\"\n",
    "\n",
    "    from math import log2\n",
    "    from itertools import product\n",
    "\n",
    "    memory = nservers * server_memory\n",
    "    val_size_bytes = 4 # one entry size in the dictionary\n",
    "    filling_rate = 0.93 # how many slots of the dictionary are used\n",
    "    l_max = log2(filling_rate * memory / val_size_bytes)\n",
    "\n",
    "    ncores = nservers * ncores_per_server\n",
    "\n",
    "    best_difficulty = 0\n",
    "    best_n = 0 # optimize: find largest n\n",
    "    best_nsenders = 0\n",
    "    best_time_phase_i = float('inf')\n",
    "    largest_difficulty = 40\n",
    "    best_l = 0\n",
    "    \n",
    "    for nsenders, difficulty in product(range(1, ncores-nservers + 1), range(0, largest_difficulty)):\n",
    "        nreceivers = ncores - nsenders\n",
    "        l = min(l_max, regen_msg_l(difficulty, nhashes_stored))\n",
    "\n",
    "        #print(f\"l={l}, nsenders={nsenders}, difficulty={difficulty}, l_regen = {regen_msg_l( difficulty, nhashes_stored)}\")\n",
    "        t_rgen_msg = regen_msg_time(nsenders,\n",
    "                                    nreceivers,\n",
    "                                    hashes_sec_core,\n",
    "                                    dict_add_sec,\n",
    "                                    difficulty,\n",
    "                                    nhashes_stored)\n",
    "        \n",
    "        t_sec_after_regen_msg = t_sec - t_rgen_msg\n",
    "        if ( t_sec_after_regen_msg <= 0):\n",
    "            continue # skip this iteration since all time have been spent on regenrating the long message\n",
    "        \n",
    "        \n",
    "        n = largest_n(l,\n",
    "                      nsenders,\n",
    "                      nreceivers,\n",
    "                      dict_queries_sec,\n",
    "                      hashes_sec_core,\n",
    "                      difficulty,\n",
    "                      t_sec_after_regen_msg)\n",
    "\n",
    "\n",
    "        # better n, always update\n",
    "        t_phase_i = phase_i_time(l, difficulty, hashes_sec_phase_i)\n",
    "        \n",
    "        if (n > best_n  and t_phase_i <= phase_i_timeout):\n",
    "            best_n = n\n",
    "            best_l = l\n",
    "            best_difficulty = difficulty\n",
    "            best_nsenders = nsenders\n",
    "            #print(f\"better_n = {best_n}, better_l={best_l}, better_difficulty={best_difficulty}, better_nsenders={best_nsenders}, t_phase_i={seconds_2_time(t_phase_i)}\")\n",
    "            \n",
    "\n",
    "\n",
    "    return {\"n\": best_n, \"l\": best_l,\n",
    "            \"difficulty\": best_difficulty,\n",
    "            \"nsenders\": best_nsenders,\n",
    "            \"nreceivers\": ncores - nsenders}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'best_l' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mfind_best_parameters\u001b[0;34m(nservers, server_memory, ncores_per_server, nhashes_stored, dict_queries_sec, dict_add_sec, hashes_sec_core, hashes_sec_phase_i, t_sec, phase_i_timeout)\u001b[0m\n\u001b[1;32m    127\u001b[0m         best_nsenders \u001b[38;5;241m=\u001b[39m nsenders\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;66;03m#print(f\"better_n = {best_n}, better_l={best_l}, better_difficulty={best_difficulty}, better_nsenders={best_nsenders}, t_phase_i={seconds_2_time(t_phase_i)}\")\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_n, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mbest_l\u001b[49m,\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifficulty\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_difficulty,\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnsenders\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_nsenders,\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnreceivers\u001b[39m\u001b[38;5;124m\"\u001b[39m: ncores \u001b[38;5;241m-\u001b[39m nsenders}\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'best_l' referenced before assignment"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# best parameters\n",
    "best_parms = find_best_parameters(nservers,\n",
    "                     server_memory,\n",
    "                     ncores_per_server,\n",
    "                     nhashes_stored,\n",
    "                     dict_queries_sec,\n",
    "                     dict_add_sec,\n",
    "                     hashes_sec_core,\n",
    "                     hashes_sec_phase_i,\n",
    "                     t_sec)\n",
    "\n",
    "print(best_parms)\n",
    "\n",
    "nsenders = best_parms[\"nsenders\"]\n",
    "nreceivers = best_parms[\"nreceivers\"]\n",
    "difficulty = best_parms[\"difficulty\"]\n",
    "l = best_parms[\"l\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# how long phase_i will take using the best parameters?\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m seconds_2_time(phase_i_time(\u001b[43ml\u001b[49m, difficulty, hashes_sec_phase_i))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "# how long phase_i will take using the best parameters?\n",
    "seconds_2_time(phase_i_time(l, difficulty, hashes_sec_phase_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how long regenerating the long message again will take?\n",
    "seconds_2_time(regen_msg_time(nsenders,\n",
    "                   nreceivers,\n",
    "                   hashes_sec_core,\n",
    "                   dict_add_sec,\n",
    "                   difficulty,\n",
    "                   nhashes_stored))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "dict_queries_sec = 2^22.963350\n",
    "log2(33767312.397134)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.7",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
